{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Spell Correction for Roman Urdu.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJ09KYJzZEQB"
      },
      "source": [
        "**Author:**  M. Adil Fayyaz\n",
        "\n",
        "\n",
        "**Email:** adilfayyaz6@gmail.com\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pCc61YLU_BRV"
      },
      "source": [
        "# Import Libraries\n",
        "import nltk\n",
        "from nltk.probability import ConditionalFreqDist\n",
        "import copy\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qlEtNRp3ZsZD"
      },
      "source": [
        "# File Reading"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QvRk1sVGZ0go"
      },
      "source": [
        "Read the data.txt which will be used as our Vocabulary "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X3OZe6XjTo4p",
        "outputId": "c35fc32a-16f3-4047-9e3d-603ed2e2ccfb"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "with open('/content/drive/MyDrive/data.txt','r') as f:\n",
        "  lines = f.readlines()\n",
        "data = \"\"\n",
        "# Append the lines into a string\n",
        "for i in lines:\n",
        "    data+=i\n",
        "data=data.split('\\n')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ETAk6y4IZ8BT"
      },
      "source": [
        "Read the misspellings.txt "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQ3QWWxZWtha"
      },
      "source": [
        "with open('/content/drive/MyDrive/misspellings.txt','r') as f:\n",
        "  lines = f.readlines()\n",
        "misspelled = \"\"\n",
        "for i in lines:\n",
        "    misspelled+=i\n",
        "misspelled=misspelled.split('\\n')\n",
        "misspelled\n",
        "# Create a dictionary which will store the correct word as key and a list of \n",
        "# wrong words as the value\n",
        "misspellings = {}\n",
        "firstRow = 1\n",
        "for row in misspelled:\n",
        "  if firstRow:\n",
        "    firstRow = 0\n",
        "  else:\n",
        "    # Slice the string read according to commas and tabs\n",
        "    correct_word = row.split(',')[0]\n",
        "    wrong_words = row.split(',')[-1]\n",
        "    wrong_words = wrong_words[1:]\n",
        "    wrong_words_list = wrong_words.split('\\t')\n",
        "    misspellings[correct_word] = wrong_words_list\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQuecDOlae_v"
      },
      "source": [
        "# Language Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N0Ep_gd0aqWR"
      },
      "source": [
        "Create a unigrams list. This list contains the words existing in the vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aT_YL_Mgg2-l"
      },
      "source": [
        "unigrams = list()\n",
        "for i in range(len(data)):\n",
        "  words = data[i].split()\n",
        "  for j in range(len(words)):\n",
        "    w1 = words[j]\n",
        "    unigrams.append(w1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JbHkjoxTa7Fl"
      },
      "source": [
        "Calculate the actual value of unigrams, i.e. count the number of occurences that a particular word occured in the vocabulary. Store this in a dictionary, where the key represents the word and the value represents the count.\n",
        "\n",
        "Store the Unique words, i.e. the keys list in a separate variable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBy1e5UtQjec"
      },
      "source": [
        "unigram_word_dictionary = {}\n",
        "for w in unigrams:\n",
        "  if unigram_word_dictionary.get(w):\n",
        "    unigram_word_dictionary[w] += 1\n",
        "  else:\n",
        "    unigram_word_dictionary[w] = 1\n",
        "global UniqueWords\n",
        "UniqueWords = unigram_word_dictionary.keys()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pooMQlJLbgeZ"
      },
      "source": [
        "Calculate the count unigram used to count the characters existing in the vocabulary ( Needed to calculate P(x|w) ). Store the unigram in a dictionary, where the key represents an alphabet and the value represents the number of times that character appeared in the vocabulary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mPAhu3FuYw0h"
      },
      "source": [
        "# Make Unigrams for the Characters\n",
        "count_unigram_prob = {} # Empty dictionary \n",
        "for word in unigrams:\n",
        "  for alphabet in word:\n",
        "    if alphabet in count_unigram_prob: # If alphabet already exists in the dict\n",
        "      count_unigram_prob[alphabet] += 1\n",
        "    else: # If alphabet read for the first time\n",
        "      count_unigram_prob[alphabet] = 1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-gjmLqImcCIQ"
      },
      "source": [
        "Calculate the count bigram used to count the characters that appear consecutively in the vocabulary ( Needed to calculate P(x|w) ). Store the bigram in a dictionary, where the key represents a tuple of two alphabets and the value represents the number of times the two characters appeared consecutively in the vocabulary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VorGLvAPa80I"
      },
      "source": [
        "# Make Bigrams for the Characters\n",
        "count_bigram = {} # Empty Dictionary\n",
        "for correctWord in unigrams:\n",
        "  correctWord = '#' + correctWord\n",
        "  for x in range(len(correctWord) - 1): \n",
        "    w1 = correctWord[x]\n",
        "    w2 = correctWord[x+1]\n",
        "    if tuple((w1,w2)) in count_bigram: # If tuple already exists in the dict\n",
        "      count_bigram[tuple((w1,w2))] += 1\n",
        "    else: # If the tuple is read for the first time\n",
        "      count_bigram[tuple((w1,w2))] = 1 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8gwC7dWczxY"
      },
      "source": [
        "Function that calculates the probability of a word. Uses the unigram word dictionary, used above to train the model, to return the probability of a word appearing given a vocabulary. i.e. P(w) -> prior"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8iiWjz6qHiKj"
      },
      "source": [
        "# Language Model\n",
        "# Train the Unigram model -> P(w)\n",
        "\n",
        "def getUnigramProbabilities(word): \n",
        "  if unigram_word_dictionary.get(word):\n",
        "    return unigram_word_dictionary[word]/float(len(unigrams))  # Get word from dict, divide by number of words in vocab\n",
        "  else:\n",
        "    return -1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t4TLZ7ZhdPEv"
      },
      "source": [
        "# Error Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vx1HkmWnddYh"
      },
      "source": [
        "Function getEditOperation takes two parameters. w represents the correct word and x represents the typed word. Returns the operation and x, y coordinates to be added in the confusion matrix \n",
        "\n",
        "---\n",
        "\n",
        "**Logic:** Compare the length between the two strings. According to the length find out if the operation was an insert or delete operation (Where the difference between the strings will vary by length 1). If the length of the strings is equal, then the words either have a transpose or substitute operation. To calculate the transpose operation between two strings sort both the strings and compare them, if they are equal and the index of the misplaced word is varied by length 1 (To ensure 1 edit dist) then the operation is transpose, otherwise it is a substitution operation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sD4CSaNsca6U"
      },
      "source": [
        "def getEditOperation(w,x):\n",
        "  # If both words are different\n",
        "  if w != x:\n",
        "    w_list = list(w)\n",
        "    x_list = list(x)\n",
        "    # INSERT\n",
        "    if len(w) <= len(x) - 1:\n",
        "      foundInsert = 0\n",
        "      for j in range(len(x_list) - 1):\n",
        "        if x_list[j] != w_list[j] and j == 0:\n",
        "          break\n",
        "        if x_list[j] != w_list[j]:\n",
        "          foundInsert = 1\n",
        "          # The last letter of w is x and the current letter is y\n",
        "          x = w_list[j-1]\n",
        "          y = x_list[j]\n",
        "          break\n",
        "      if foundInsert:    \n",
        "        return \"insert\", x, y\n",
        "      else:\n",
        "        # Insert operation at the first index\n",
        "        if x_list[0] != w_list[0]:\n",
        "          return \"insert\", '#', x_list[0]\n",
        "        # Insert operation at the last index\n",
        "        else:\n",
        "          return \"insert\", w_list[-1], x_list[-1]\n",
        "\n",
        "    # DELETE\n",
        "    elif len(w) >= len(x) + 1:\n",
        "      foundDelete = 0\n",
        "      for i in range(len(w_list) - 1):\n",
        "        if x_list[i] != w_list[i] and i==0:\n",
        "          break\n",
        "        if x_list[i] != w_list[i]:\n",
        "          foundDelete = 1\n",
        "          x = w_list[i-1]\n",
        "          y = w_list[i]\n",
        "          break\n",
        "      if foundDelete:\n",
        "        \n",
        "        return \"delete\", x, y\n",
        "      else:\n",
        "        # Delete Operation at the first index\n",
        "        if x_list[0] != w_list[0]:\n",
        "          return \"delete\", '#', w_list[0]\n",
        "        else:\n",
        "          return 'delete', w_list[-2], w_list[-1]\n",
        "\n",
        "    elif len(w) == len(x): # Either substitute or transpose\n",
        "      copyW = copy.deepcopy(w)\n",
        "      copyX = copy.deepcopy(x)\n",
        "      # SUBSTITUTE\n",
        "      if sorted(copyW) != sorted(copyX):  \n",
        "        for i in range(len(w_list)):\n",
        "            if w_list[i] != x_list[i]:\n",
        "              return \"substitute\", x_list[i], w_list[i]\n",
        "      # TRANSPOSE\n",
        "      else:\n",
        "        istrans = 0\n",
        "        for a in range(len(x)-1):\n",
        "          if x[a] == w[a+1] and x[a+1] == w[a]: # Check if indexes swapped are consecutive\n",
        "            istrans = 1\n",
        "            break\n",
        "        if istrans:\n",
        "          for i in range(len(w_list)-1):\n",
        "            if w_list[i] != x_list[i]:\n",
        "              return \"transpose\", w_list[i], w_list[i+1] \n",
        "  else:\n",
        "    return \"same\", -1, -1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_-iWRFkfSL2"
      },
      "source": [
        "Create the Confusion Matrix for all the Insert, Delete, Transpose and Substitute Tables. Use the misspellings to populate the DataFrames using the getEditOperation function defined above"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_1_JxwoPWyM7",
        "outputId": "3281435c-976d-4879-f3c7-17a6f289ef9c"
      },
      "source": [
        "# Error Model -> P(x|w)\n",
        "# Character level insert, delete, transpose and substitue tables\n",
        "\n",
        "# X and Y labels for the DataFrames\n",
        "x_values = ['#','a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y','z']\n",
        "y_values = ['a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y','z']\n",
        "# Create dataframes for the confusion matrices\n",
        "# Insert DF\n",
        "InsertDF = pd.DataFrame(columns = y_values, index = x_values)\n",
        "InsertDF.fillna(0, inplace = True) \n",
        "\n",
        "# Delete DF\n",
        "DeleteDF = pd.DataFrame(columns = y_values, index = x_values)\n",
        "DeleteDF.fillna(0, inplace = True) \n",
        "\n",
        "# Substitue DF\n",
        "SubstituteDF = pd.DataFrame(columns = y_values, index = x_values)\n",
        "SubstituteDF.fillna(0, inplace = True) \n",
        "\n",
        "#Transpose DF\n",
        "TransposeDF = pd.DataFrame(columns = y_values, index = x_values)\n",
        "TransposeDF.fillna(0, inplace = True) \n",
        "\n",
        "\n",
        "for correctWord in misspellings:\n",
        "  # Populate the confusion matrices\n",
        "  for incorrectWord in misspellings[correctWord]:\n",
        "    editOperation, x, y = getEditOperation(correctWord,incorrectWord)\n",
        "    if editOperation == 'insert':\n",
        "      InsertDF[y][x] += 1\n",
        "    elif editOperation == 'delete':\n",
        "      DeleteDF[y][x] += 1\n",
        "    elif editOperation == 'substitute':\n",
        "      SubstituteDF[y][x] += 1\n",
        "    elif editOperation == 'transpose':\n",
        "      TransposeDF[y][x] += 1\n",
        "\n",
        "print(InsertDF)\n",
        "print(\"*******\")\n",
        "print(DeleteDF)\n",
        "print(\"*******\")\n",
        "print(SubstituteDF)\n",
        "print(\"*******\")\n",
        "print(TransposeDF)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     a    b    c    d    e    f    g  ...    t    u    v    w    x    y    z\n",
            "#  594  650  705  682  710  707  683  ...  718  730  732  710  771  681  744\n",
            "a  548  693  644  652  662  641  656  ...  620  670  633  626  656  634  648\n",
            "b   57   81   95   97   60   86   66  ...   96   98   90  100   97   81   88\n",
            "c   55   64   69   66   58   67   68  ...   76   60   61   59   79   69   55\n",
            "d   99  109  127  136   97  148  114  ...  125  126  131  115  130  131  149\n",
            "e  273  298  248  230  235  272  270  ...  236  277  286  259  243  241  270\n",
            "f   23   39   58   38   32   44   38  ...   40   34   43   39   28   39   31\n",
            "g   56   88   88   80   74   74   74  ...   85   72   70   87   65   84   81\n",
            "h  112  206  210  237  185  228  234  ...  219  222  222  232  215  224  218\n",
            "i  229  254  259  252  250  246  248  ...  240  276  275  278  242  266  254\n",
            "j   38   53   53   42   50   50   49  ...   40   33   54   55   39   48   61\n",
            "k   88  123  119  136  113  110  137  ...  112  104  112  112  127   93  119\n",
            "l  113  145  157  126  126  131  167  ...  134  120  136  151  146  139  123\n",
            "m   79  127  146  124  109  124  125  ...  107  105  119  133  116  114  123\n",
            "n  190  213  255  190  203  223  221  ...  199  205  243  232  241  209  256\n",
            "o  173  199  188  182  187  172  213  ...  211  169  199  190  213  192  206\n",
            "p   42   69   88   73   50   53   64  ...   64   55   78   63   67   52   71\n",
            "q   17   12   23   13   25   17   23  ...   27   16   18   15   15   24   20\n",
            "r  162  223  233  220  198  207  190  ...  212  193  216  231  218  243  206\n",
            "s  147  178  182  179  166  206  186  ...  161  172  198  216  198  181  170\n",
            "t  145  186  184  202  155  203  210  ...  192  200  179  204  211  186  220\n",
            "u  126  115  132  119  123  114  120  ...  118  121  104  110  122  127  105\n",
            "v   29   23   27   22   15   22   23  ...   18   17   17   33   34   25   27\n",
            "w   17   34   35   38   50   39   37  ...   39   41   38   35   43   44   45\n",
            "x    8    6    5    4    8    4    8  ...    8    5    5    1    9    7    3\n",
            "y   50  108  100   94   88  117  103  ...   84   98   82  112  116  100   89\n",
            "z   27   37   32   28   31   40   41  ...   36   29   35   34   30   32   25\n",
            "\n",
            "[27 rows x 26 columns]\n",
            "*******\n",
            "    a   b   c   d   e  f   g   h   i  j  ...  q   r   s   t   u  v  w  x   y  z\n",
            "#  40  23  18  15  13  9   6  19  18  9  ...  5  15  27  20   8  4  2  0   0  4\n",
            "a  14   9   8  16   2  3   9  15  11  3  ...  2  40   9  40   0  3  4  1  12  6\n",
            "b  21   0   0   1   6  1   0   5   6  0  ...  0   5   0   0   6  0  0  0   0  3\n",
            "c   5   0   0   0   6  0   0  21   2  0  ...  0   2   1   4   1  0  0  0   0  0\n",
            "d  18   0   0   0  14  0   2   4  13  0  ...  0   0   1   0   4  0  1  0   1  0\n",
            "e   6   1   8  12  14  1   3   6   3  1  ...  0  21   9   6   0  1  0  2   2  3\n",
            "f   5   0   0   0   1  1   0   0   3  0  ...  0   2   1   0   2  0  0  0   0  1\n",
            "g  15   2   0   0   3  0   2   7   6  0  ...  0   0   0   0   4  0  0  0   0  1\n",
            "h  58   1   0   0  14  0   0   0  15  0  ...  0   3   0   3  12  0  1  0   2  0\n",
            "i   4   2   5   7   1  2   2   1   0  1  ...  1  11  13  12   0  2  1  0   6  2\n",
            "j  11   0   0   0   0  0   0   4   5  0  ...  0   0   1   0   5  0  1  0   0  0\n",
            "k  17   0   0   0   7  0   0  14  10  0  ...  0   4   1   2   3  0  0  0   1  0\n",
            "l  29   1   0   1  11  1   1   2  13  0  ...  1   0   0   1   1  0  2  1   4  0\n",
            "m  33   1   0   2   4  0   0   2  10  1  ...  0   1   1   1   6  0  1  0   1  0\n",
            "n  25   2   6  10   7  0  14   1   7  1  ...  1   1   4   9   2  1  1  0   3  1\n",
            "o   2   2   1   7   2  0   2   0   1  1  ...  0  18   5   2   2  2  2  0   2  1\n",
            "p   9   0   0   1   7  0   0   3   3  0  ...  0   7   1   0   3  0  0  0   1  0\n",
            "q   1   1   0   0   1  0   0   0   1  0  ...  0   0   1   0   1  0  0  0   0  0\n",
            "r  29   0   0   6  12  1   1   1  17  2  ...  0   2   3   3   3  1  0  0   7  1\n",
            "s  23   1   1   0  16  0   0  19   7  0  ...  0   1   4  10   6  1  0  0   1  0\n",
            "t  28   0   0   1  19  0   0   6  12  0  ...  2   7   1   1   5  1  2  0   3  0\n",
            "u   0   4   1   5   1  0   1   4   1  1  ...  1  15   9   3   0  0  2  0   0  1\n",
            "v   3   0   0   0   5  0   0   0   4  0  ...  0   0   0   0   0  0  0  0   0  0\n",
            "w  15   1   0   1   1  0   0   1   3  0  ...  0   1   0   0   0  0  0  0   0  0\n",
            "x   1   0   0   0   1  0   0   0   1  0  ...  0   0   0   0   0  0  0  0   0  0\n",
            "y  11   0   0   2   4  0   0   0   2  0  ...  0   0   0   1   0  0  0  0   0  1\n",
            "z   4   1   0   1   2  0   0   0   0  0  ...  0   1   0   0   0  0  0  0   1  0\n",
            "\n",
            "[27 rows x 26 columns]\n",
            "*******\n",
            "     a   b   c    d    e   f   g    h  ...    s    t    u   v   w   x    y   z\n",
            "#    0   0   0    0    0   0   0    0  ...    0    0    0   0   0   0    0   0\n",
            "a    0  78  66  120  184  28  48  191  ...  145  160   99  17  30   1   73  26\n",
            "b  642   0  65  116  248  24  61  196  ...  179  187  107  24  28   5   85  31\n",
            "c  634  78   0  115  274  35  70  216  ...  193  183  120  19  30   4   91  30\n",
            "d  639  85  68    0  303  37  69  201  ...  149  173  117  17  30   2   83  22\n",
            "e  580  74  68  110    0  33  62  207  ...  156  164   95  18  29   4   79  28\n",
            "f  645  79  63  118  255   0  78  227  ...  157  188   99  17  40   5   85  29\n",
            "g  642  75  68   88  262  34   0  187  ...  160  179  118  19  30   3   89  27\n",
            "h  613  91  59  103  246  28  61    0  ...  149  174  113  26  39  10   83  36\n",
            "i  560  79  52   94  212  30  53  201  ...  165  162   96  18  39   3   74  29\n",
            "j  627  81  57  138  242  34  77  199  ...  166  165  104  11  34   4   96  32\n",
            "k  648  81  63   95  272  29  63  205  ...  159  183  102  15  26   4   83  22\n",
            "l  638  74  76   99  288  18  82  209  ...  153  171  108  22  27   3   80  30\n",
            "m  642  69  65  106  246  33  68  213  ...  164  175  103  16  32   3   76  20\n",
            "n  659  79  51   98  251  26  53  196  ...  178  146   97  17  34   6   77  30\n",
            "o  598  79  67  102  228  33  64  203  ...  175  193   96  24  30   4   69  28\n",
            "p  628  76  57   96  238  26  66  213  ...  165  188  137  16  42   3   75  25\n",
            "q  690  83  64  122  251  34  60  231  ...  162  179  108  13  36   9   93  30\n",
            "r  610  69  43   97  276  28  66  197  ...  163  155  109  13  33   4   76  24\n",
            "s  623  60  74  112  239  33  76  233  ...    0  141   98  21  24   5   80  29\n",
            "t  623  75  64   96  260  33  65  191  ...  170    0  102  16  31   3   77  30\n",
            "u  652  80  60  124  221  35  60  199  ...  176  180    0  15  30   4   87  31\n",
            "v  701  95  79  125  298  37  77  193  ...  150  184  110   0  42  12  109  31\n",
            "w  616  74  70  115  258  24  62  208  ...  164  190  121  18   0   1   96  34\n",
            "x  614  90  81  139  239  38  83  201  ...  204  191  118  19  50   0   90  32\n",
            "y  612  69  82   91  255  33  59  198  ...  148  165  107  16  25   1    0  31\n",
            "z  660  86  73  105  260  42  63  231  ...  166  166  122  22  36   3   78   0\n",
            "\n",
            "[27 rows x 26 columns]\n",
            "*******\n",
            "    a   b  c   d   e  f   g   h   i   j  ...  q   r   s   t   u  v  w  x   y  z\n",
            "#   0   0  0   0   0  0   0   0   0   0  ...  0   0   0   0   0  0  0  0   0  0\n",
            "a   0  20  4  15   5  8  16  21  29  10  ...  4  57  32  38   4  4  7  0  38  5\n",
            "b  27   0  0   0   4  0   0  16   5   0  ...  0   5   1   1   7  0  0  0   0  0\n",
            "c   9   0  0   0   4  0   0  38   3   0  ...  0   2   1   4   0  0  0  0   0  0\n",
            "d  24   0  0   0  19  0   2   7  16   0  ...  0   3   1   1   3  1  0  0   2  0\n",
            "e  10   0  1  13   0  2   3  12   1   2  ...  0  23  15  12   2  1  3  0   3  2\n",
            "f   9   0  1   0   3  0   0   0   7   0  ...  0   1   1   2   2  0  0  0   0  0\n",
            "g  14   0  0   0   8  0   0   9   2   0  ...  0   2   3   1   2  0  1  0   1  0\n",
            "h  58   2  1   0  16  0   0   0  21   0  ...  1   3   1  11  13  0  1  0   4  2\n",
            "i   6   4  8   8   4  2   2   1   0   4  ...  2  17  14  16   0  3  1  2   9  1\n",
            "j  14   0  0   1   5  0   1   3   3   0  ...  0   0   0   0   5  0  0  0   0  0\n",
            "k  27   1  1   0   5  0   0  27   9   0  ...  0   3   5   3   4  0  1  0   0  0\n",
            "l  27   0  0   7  19  0   3   2  11   0  ...  1   0   3   8   5  0  1  0   2  2\n",
            "m  33   1  0   0  15  0   1   2  14   1  ...  0   4   0   3   7  0  0  0   2  1\n",
            "n  32   0  6  19  14  0  18   1   8   3  ...  0   1  10  16   1  0  1  0   8  0\n",
            "o   1   1  3   7   2  2   3   2   4   3  ...  0  16   6  12   6  1  3  0   0  1\n",
            "p  10   0  0   2   4  0   0   6   8   0  ...  0   4   1   0   1  0  0  0   1  0\n",
            "q   4   0  0   0   2  0   0   0   2   0  ...  0   0   0   2   5  0  0  0   0  0\n",
            "r  37   0  4   4  26  1   2   2  20   1  ...  1   0  11   9   4  1  4  0   2  1\n",
            "s  33   1  1   1   4  0   0  24  12   0  ...  0   2   0  15   6  1  4  0   0  0\n",
            "t  43   1  0   0  23  0   0  23  25   0  ...  0  11   2   0   8  0  1  0   2  0\n",
            "u   2   8  1   4   4  1   3   0   1   2  ...  0  14   6   5   0  0  1  0   0  2\n",
            "v   6   0  0   0   6  0   0   0   3   1  ...  0   0   1   0   1  0  1  0   0  0\n",
            "w  15   0  0   0   1  0   0   1   3   0  ...  0   0   2   0   0  0  0  0   0  0\n",
            "x   0   0  1   0   0  0   0   0   2   0  ...  1   0   0   0   0  0  0  0   1  0\n",
            "y  18   2  0   0   8  0   0   0   1   0  ...  0   1   0   1   3  0  0  0   0  0\n",
            "z  10   0  0   0   1  0   1   0   4   0  ...  1   1   0   1   1  0  0  0   1  0\n",
            "\n",
            "[27 rows x 26 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-86QxUrf6LK"
      },
      "source": [
        "Returns the value against the tuple i, j in the count bigram defined above"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLOqR4cOhAf4"
      },
      "source": [
        "def getCountBigram(i, j):\n",
        "  # Return the value against the tuple i, j in the \n",
        "  # count bigram\n",
        "  return (count_bigram[i,j])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "292DXZBQgF_-"
      },
      "source": [
        "Returns the number of character counts in the unigram calculated above "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1PDAEZNYWwyB"
      },
      "source": [
        "# Count of individual alphabets in correct misspellings dictionary\n",
        "def getCountOfWi(character):\n",
        "  # If the character is '#' , we know that # technically is the starting character\n",
        "  # of every word, so safe to assume that the number of times '#' will appear in the\n",
        "  # vocabulary will be equal to the number of words.\n",
        "  # Note - here unigrams represents individual words list\n",
        "  if character == '#':\n",
        "    return len(unigrams)\n",
        "  \n",
        "  return count_unigram_prob[character] "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_F3hlNGqhDI9"
      },
      "source": [
        "Function getProbabilityOfWord takes the correct word and the typed word as parameter. Computes the value of P(x|w) by fetching the edit operation performed between both the words and then returning the probability according to the individual formulas of Insert, Delete, Substitute, and Transpose"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LnlJqgCtQP6j"
      },
      "source": [
        "def getProbabilityOfWord(w,x):\n",
        "  operation, i, j = getEditOperation(w,x)\n",
        "  if operation == 'insert':\n",
        "    probability = InsertDF[j][i]/getCountOfWi(i)\n",
        "  elif operation == 'delete':\n",
        "    probability = DeleteDF[j][i]/getCountBigram(i,j)\n",
        "  elif operation == 'substitute':\n",
        "    probability = SubstituteDF[j][i]/getCountOfWi(j)\n",
        "  elif operation == 'transpose':\n",
        "    probability = TransposeDF[j][i]/getCountBigram(i,j)\n",
        "  elif operation == 'same':\n",
        "    probability = 1\n",
        "  return probability\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jED3LVu0hj9f"
      },
      "source": [
        "# Candidate Words Generation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-NbcnTf5hpWG"
      },
      "source": [
        "Function isTranspose returns a bool if the passed strings w and x have a transpose operation between them"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qOU_XaejiMY"
      },
      "source": [
        "# Function checks if two words have a transpose operation between them\n",
        "def isTranspose(w,x):\n",
        "  if sorted(w) == sorted(x):\n",
        "    for a in range(len(x)-1):\n",
        "      if x[a] == w[a+1] and x[a+1] == w[a]: # Checks if the alphabets were consecutive\n",
        "        return True\n",
        "  return False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xFRoBBJ5h24e"
      },
      "source": [
        "Function getEditDistance calculates the edit distance given two strings w and x using the levenshtein distance formula - to measure the difference between two sequences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9UU_PurefS4"
      },
      "source": [
        "# Calculate the edit distance between the given and candidate word\n",
        "def getEditDistance(w,x):\n",
        "  len_w = len(w)\n",
        "  len_x = len(x)\n",
        "  edits = [[0 for e in range(len_x + 1)] for u in range(len_w + 1)]\n",
        "  for i in range(len(w) + 1):\n",
        "    for j in range(len(x) + 1):\n",
        "      if i == 0:\n",
        "        edits[i][j] = j\n",
        "      elif j == 0:\n",
        "        edits[i][j] = i\n",
        "      elif w[i-1] == x[j-1]:\n",
        "        edits[i][j] = edits[i-1][j-1]\n",
        "      else:\n",
        "        edits[i][j] = 1 + min(edits[i-1][j], edits[i][j-1], edits[i-1][j-1])\n",
        "  return edits[len_w][len_x]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmLYz0LWiPJf"
      },
      "source": [
        "Function getCandidateWords, returns the candidates 1 edit distance away from the typed word - x. Iterates over the set of unique words in our vocabulary and calculates the edit distance between them and the typed word. Adds them to a list of candidate words if the edit distance is equal to 1.\n",
        "\n",
        "Note: The function returns a single word if the typed word x already exists in the vocabulary. In this case, the same word is returned. I.e. Edit distance calculated between both the words(same) will be equal to zero (0)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1jMliAqbTSq"
      },
      "source": [
        "# Given a word x, return a list of candidate words from the Vocabulary\n",
        "def getCandidateWords(x):\n",
        "  candidateWords = []\n",
        "  zeroEditCandidate = []\n",
        "  if x in UniqueWords:\n",
        "    print(\"*** Word exists in the Vocabulary ***\")\n",
        "    zeroEditCandidate.append(x)\n",
        "    return zeroEditCandidate\n",
        "  \n",
        "  for correctWord in UniqueWords:\n",
        "    editDist = getEditDistance(correctWord, x)\n",
        "    # getEditDistance returns insert, delete and subs only. However a transpose\n",
        "    # operation is considered as a substitution with edit Dist = 2. \n",
        "    # Hence, check if the words are transpose then subtract 1 from the edit dist\n",
        "    # to find the edit distance for the transpose operation\n",
        "    isTrans = isTranspose(correctWord, x)\n",
        "    if isTrans:\n",
        "      editDist -= 1\n",
        "    if editDist == 1:\n",
        "      candidateWords.append(correctWord)\n",
        "\n",
        "  availableCandidates = []\n",
        "  # Precautionary check in case the entire data is not read\n",
        "  for w in candidateWords:\n",
        "    try:\n",
        "      p = getUnigramProbabilities(w)\n",
        "      if p > 0:\n",
        "        availableCandidates.append(w)\n",
        "    except: # did not find the word in Vocab\n",
        "      xyz=1 # garbage assignment\n",
        "\n",
        "  return availableCandidates\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hA8hBSjwjAC7"
      },
      "source": [
        "# Selection Model Using ArgMax"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cPkm2Pn2jDpt"
      },
      "source": [
        "Function getProbableWord takes as parameter the typed word and returns the word with the highest probability. The probability P(x|w) is fetched from getProbabilityOfWord function and the probability P(w) is fetched from getUnigramProbabilities function. The product of both the probabilities is stores in an options dictionary with the key as a candidate word and the value as the probability.\n",
        "\n",
        "If the program finds a list of options it returns the ArgMax = Max of the list according to probability. Else, if the program does not find a candidate word, it returns None."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LuLp1h2XooCu"
      },
      "source": [
        "def getProbableWord(x):\n",
        "  candidates = getCandidateWords(x)\n",
        "  # print(candidates)\n",
        "  options = {} # Dictionary\n",
        "  for w in candidates:\n",
        "    prob_xw = getProbabilityOfWord(w,x)  # P(x|w)\n",
        "    prob_w = getUnigramProbabilities(w)  # P(w)\n",
        "    result = prob_xw * prob_w            # P(x|w) . P(w)\n",
        "    options[w] = result                  # Store the result in the dict\n",
        "    print(\"Candidate: \", w, \" Probability: \", result)\n",
        "  if options:\n",
        "    likely_word = max(options, key=options.get)  # Likely word is the word with the maximum probability \n",
        "    return likely_word\n",
        "  else: # If no options/candidates found\n",
        "    print(\"*** No Candidates Found ***\")\n",
        "    return \"None\"\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q9pQeUfGkLMt"
      },
      "source": [
        "# Testing/Output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJJZIGHvcsQg",
        "outputId": "82f04e8e-d9a9-4496-be39-92da0f1222e5"
      },
      "source": [
        "# Testing \n",
        "x = 'mujhel'\n",
        "likely = getProbableWord(x)\n",
        "print(\"Suggested Word is: \", likely)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Candidate:  mujhe  Probability:  7.450380326318264e-08\n",
            "Candidate:  mujhey  Probability:  2.231249309368189e-11\n",
            "Suggested Word is:  mujhe\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_tszCK6meCOC",
        "outputId": "c3e2b86f-8cae-4b55-d9cd-9ffb627b411d"
      },
      "source": [
        "x = 'kaesa'\n",
        "likely = getProbableWord(x)\n",
        "print(\"Suggested Word is: \",likely)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Candidate:  aesa  Probability:  1.0370924043010484e-10\n",
            "Candidate:  kaisa  Probability:  8.487599927204714e-09\n",
            "Candidate:  kesa  Probability:  2.0943405647538557e-11\n",
            "Candidate:  kasa  Probability:  1.8482692760567328e-11\n",
            "Candidate:  kaasa  Probability:  3.58351637919582e-11\n",
            "Candidate:  khesa  Probability:  2.157150194830464e-11\n",
            "Suggested Word is:  kaisa\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bUFIQeMIqbPg",
        "outputId": "dc310e32-1806-4e05-eb8a-3a97fd0f8f67"
      },
      "source": [
        "x = 'adile'\n",
        "likely = getProbableWord(x)\n",
        "print(\"Suggested Word is: \",likely)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Candidate:  adil  Probability:  4.0370865485362967e-10\n",
            "Candidate:  adle  Probability:  4.367925309691912e-12\n",
            "Candidate:  adine  Probability:  2.265205203361891e-12\n",
            "Candidate:  dile  Probability:  1.4875709653115589e-12\n",
            "Candidate:  adele  Probability:  1.220692398292538e-10\n",
            "Suggested Word is:  adil\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-1fwhOlNnR_a",
        "outputId": "7016bd66-50cd-4ee4-ff82-2aeedae54207"
      },
      "source": [
        "# Word already exists in the Vocabulary, return the same word\n",
        "x = 'nahi'\n",
        "likely = getProbableWord(x)\n",
        "print(\"Suggested Word is: \",likely)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "*** Word exists in the Vocabulary ***\n",
            "Candidate:  nahi  Probability:  0.012080763051931738\n",
            "Suggested Word is:  nahi\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-oxzverrnTKe",
        "outputId": "3e175199-db6a-4226-c3d1-f942b90bc852"
      },
      "source": [
        "# Word does not return any candidate words\n",
        "# Returns 'None' i.e. no word found\n",
        "x = 'nahasdksjai'\n",
        "likely = getProbableWord(x)\n",
        "print(\"Suggested Word is: \",likely)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "*** No Candidates Found ***\n",
            "Suggested Word is:  None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gqo37WBmgPk1",
        "outputId": "21dbd7ec-2476-4993-dbcd-b03c751e23d4"
      },
      "source": [
        "x = 'kitaa'\n",
        "likely = getProbableWord(x)\n",
        "print(\"Suggested Word is: \",likely)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Candidate:  kiaa  Probability:  7.180690348198157e-12\n",
            "Candidate:  kitna  Probability:  1.2963851350078707e-09\n",
            "Candidate:  kitab  Probability:  6.765369612314775e-11\n",
            "Candidate:  kita  Probability:  1.969150264291617e-11\n",
            "Candidate:  kitaab  Probability:  1.5484561487365123e-09\n",
            "Candidate:  kiyaa  Probability:  7.921392271476204e-12\n",
            "Candidate:  kitta  Probability:  5.590334732247482e-12\n",
            "Candidate:  kitana  Probability:  1.8237941720142664e-12\n",
            "Suggested Word is:  kitaab\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rcwhfMxFgTDH",
        "outputId": "d3e08cd7-030c-4694-c176-6541e5ebf448"
      },
      "source": [
        "# Word does not return any candidate words\n",
        "# Returns 'None' i.e. no word found\n",
        "x = 'karnaed'\n",
        "likely = getProbableWord(x)\n",
        "print(\"Suggested Word is: \",likely)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "*** No Candidates Found ***\n",
            "Suggested Word is:  None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5dgs1gpegbR3",
        "outputId": "c4bc6e7d-66dd-4955-c2e7-9a2316857356"
      },
      "source": [
        "x = 'usary'\n",
        "likely = getProbableWord(x)\n",
        "print(\"Suggested Word is: \",likely)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Candidate:  usay  Probability:  9.18408663826041e-09\n",
            "Candidate:  sary  Probability:  2.1389467364858627e-11\n",
            "Candidate:  umary  Probability:  2.9070395480200804e-12\n",
            "Candidate:  usar  Probability:  9.914359709551538e-13\n",
            "Suggested Word is:  usay\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}